{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6344b713",
   "metadata": {},
   "source": [
    "# Восстановление пробелов в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be61007",
   "metadata": {},
   "source": [
    "Подготовим импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938cac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in a:\\avito\\avito_test\\venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in a:\\avito\\avito_test\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in a:\\avito\\avito_test\\venv\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in a:\\avito\\avito_test\\venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in a:\\avito\\avito_test\\venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in a:\\avito\\avito_test\\venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in a:\\avito\\avito_test\\venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in a:\\avito\\avito_test\\venv\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in a:\\avito\\avito_test\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in a:\\avito\\avito_test\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp311-cp311-win_amd64.whl (2817.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp311-cp311-win_amd64.whl (5.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   ---------------------------------------- 3/3 [torchaudio]\n",
      "\n",
      "Successfully installed torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65516912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from razdel import sentenize\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from torch.optim import AdamW \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c0aff",
   "metadata": {},
   "source": [
    "Создание корпуса для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eac99681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus.txt готов! Всего строк: 36445\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"news_raw/texts\"\n",
    "output_file = \"corpus.txt\"\n",
    "\n",
    "all_files = glob.glob(os.path.join(input_folder, \"**/*.txt\"), recursive=True)\n",
    "lines = []\n",
    "\n",
    "for f in all_files:\n",
    "    with open(f, \"r\", encoding=\"utf-8\") as file:\n",
    "        html = file.read()\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        # Удаляем script и style\n",
    "        for tag in soup([\"script\", \"style\"]):\n",
    "            tag.decompose()\n",
    "\n",
    "        text = soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "        # Убираем лишние символы переноса строк\n",
    "        text = text.replace('\\u2028',' ').replace('\\u2029',' ')\n",
    "\n",
    "        # Сжимаем множественные пробелы в один\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        if text:\n",
    "            lines.append(text)\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(\"corpus.txt готов! Всего строк:\", len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6287e",
   "metadata": {},
   "source": [
    "Подготовим корпус к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302ffc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positions_from_text(s):\n",
    "    \"\"\"Возвращает индексы пробелов в строке\"\"\"\n",
    "    return [i+1 for i, c in enumerate(s[:-1]) if s[i+1].isspace()]\n",
    "\n",
    "def remove_spaces(s):\n",
    "    \"\"\"Удаляет пробелы\"\"\"\n",
    "    return s.replace(\" \", \"\")\n",
    "\n",
    "def extract_sentences_from_file(filename):\n",
    "    \"\"\"Читает файл и разбивает на предложения с помощью razdel\"\"\"\n",
    "    sentences = []\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            for sent in sentenize(line):\n",
    "                text = sent.text.strip()\n",
    "                if len(text) > 3:  # минимальная длина предложения\n",
    "                    sentences.append(text)\n",
    "    return sentences\n",
    "\n",
    "def generate_synthetic_dataset(sentences, seed=42, val_size=0.1, test_size=0.1):\n",
    "    random.seed(seed)\n",
    "    data = []\n",
    "    for i, line in enumerate(sentences):\n",
    "        line_norm = \" \".join(line.split())  # убираем лишние пробелы\n",
    "        no_space = remove_spaces(line_norm)\n",
    "        positions = positions_from_text(line_norm)\n",
    "        data.append({\n",
    "            \"id\": i,\n",
    "            \"text\": line_norm,\n",
    "            \"no_space\": no_space,\n",
    "            \"space_positions\": json.dumps(positions)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    # Делим на train/val/test\n",
    "    train_df, temp_df = train_test_split(df, test_size=val_size+test_size, random_state=seed)\n",
    "    val_ratio = val_size / (val_size + test_size)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=1-val_ratio, random_state=seed)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a5fc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Извлекаем предложения...\n",
      "Всего предложений: 293223\n",
      "Генерируем синтетический датасет...\n",
      "Синтетический датасет создан!\n",
      "Train: 234578, Val: 29322, Test: 29323\n"
     ]
    }
   ],
   "source": [
    "corpus_file = \"corpus.txt\"  \n",
    "if not os.path.exists(corpus_file):\n",
    "    raise FileNotFoundError(f\"Файл {corpus_file} не найден!\")\n",
    "\n",
    "print(\"Извлекаем предложения...\")\n",
    "sentences = extract_sentences_from_file(corpus_file)\n",
    "print(f\"Всего предложений: {len(sentences)}\")\n",
    "\n",
    "print(\"Генерируем синтетический датасет...\")\n",
    "train_df, val_df, test_df = generate_synthetic_dataset(sentences)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "train_df.to_csv(\"data/train.csv\", index=False)\n",
    "val_df.to_csv(\"data/val.csv\", index=False)\n",
    "test_df.to_csv(\"data/test.csv\", index=False)\n",
    "\n",
    "print(\"Синтетический датасет создан!\")\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c9f76e",
   "metadata": {},
   "source": [
    "Так как данные из новостей, они могут пересекаться, проверим и удалим дубликаты во всех датасетах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9746ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Пересечение train & val:\n",
      "  ID пересекаются: 0\n",
      "  Text пересекаются: 595\n",
      "\n",
      "Пересечение train & test:\n",
      "  ID пересекаются: 0\n",
      "  Text пересекаются: 603\n",
      "\n",
      "Пересечение val & test:\n",
      "  ID пересекаются: 0\n",
      "  Text пересекаются: 130\n"
     ]
    }
   ],
   "source": [
    "def check_dataset_overlap(train_file, val_file, test_file):\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    val_df = pd.read_csv(val_file)\n",
    "    test_df = pd.read_csv(test_file)\n",
    "\n",
    "    datasets = {\"train\": train_df, \"val\": val_df, \"test\": test_df}\n",
    "    pairs = [(\"train\", \"val\"), (\"train\", \"test\"), (\"val\", \"test\")]\n",
    "\n",
    "    for a, b in pairs:\n",
    "        df_a, df_b = datasets[a], datasets[b]\n",
    "\n",
    "        id_overlap = set(df_a['id']).intersection(df_b['id'])\n",
    "        text_overlap = set(df_a['text']).intersection(df_b['text'])\n",
    "\n",
    "        print(f\"\\nПересечение {a} & {b}:\")\n",
    "        print(f\"  ID пересекаются: {len(id_overlap)}\")\n",
    "        print(f\"  Text пересекаются: {len(text_overlap)}\")\n",
    "\n",
    "check_dataset_overlap(\n",
    "    \"data/train.csv\",\n",
    "    \"data/val.csv\",\n",
    "    \"data/test.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bf17977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пересечения удалены. Новые размеры:\n",
      "Train: 234578, Val: 28628, Test: 28568\n"
     ]
    }
   ],
   "source": [
    "val_df = val_df[~val_df['text'].isin(train_df['text'])]\n",
    "test_df = test_df[~test_df['text'].isin(train_df['text'])]\n",
    "test_df = test_df[~test_df['text'].isin(val_df['text'])]\n",
    "\n",
    "val_df.to_csv(\"data/val.csv\", index=False)\n",
    "test_df.to_csv(\"data/test.csv\", index=False)\n",
    "\n",
    "print(\"Пересечения удалены. Новые размеры:\")\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd6354",
   "metadata": {},
   "source": [
    "Подготовка к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6489dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "MAX_LEN = 128    \n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "\n",
    "CHECKPOINT_DIR = \"./checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4fa413",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "val_df   = pd.read_csv(\"data/val.csv\")\n",
    "test_df  = pd.read_csv(\"data/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1e275f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>no_space</th>\n",
       "      <th>space_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10782</th>\n",
       "      <td>221169</td>\n",
       "      <td>Атмосфера Земли, для сравнения, состоит на 21 ...</td>\n",
       "      <td>АтмосфераЗемли,длясравнения,состоитна21процент...</td>\n",
       "      <td>[9, 16, 20, 31, 39, 42, 45, 53, 56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57340</th>\n",
       "      <td>172891</td>\n",
       "      <td>Компания также заверила, что этот факт не окаж...</td>\n",
       "      <td>Компаниятакжезаверила,чтоэтотфактнеокажетнегат...</td>\n",
       "      <td>[8, 14, 24, 28, 33, 38, 41, 48, 60, 72, 75, 83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26451</th>\n",
       "      <td>184070</td>\n",
       "      <td>Об этом сообщается на сайте кинотеатра.</td>\n",
       "      <td>Обэтомсообщаетсянасайтекинотеатра.</td>\n",
       "      <td>[2, 7, 18, 21, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47327</th>\n",
       "      <td>31904</td>\n",
       "      <td>По данным газеты \"Комсомольская правда\", его з...</td>\n",
       "      <td>Поданнымгазеты\"Комсомольскаяправда\",егозадержа...</td>\n",
       "      <td>[2, 9, 16, 31, 40, 44, 54, 58, 66, 74, 82, 92,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161950</th>\n",
       "      <td>22579</td>\n",
       "      <td>Об этом заявил министр обороны временного прав...</td>\n",
       "      <td>Обэтомзаявилминистроборонывременногоправительс...</td>\n",
       "      <td>[2, 7, 14, 22, 30, 41, 55, 62, 75, 79, 89, 99,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28327</th>\n",
       "      <td>59409</td>\n",
       "      <td>При этом не уточняется, почему для ответной ак...</td>\n",
       "      <td>Приэтомнеуточняется,почемудляответнойакциипотр...</td>\n",
       "      <td>[3, 8, 11, 23, 30, 34, 43, 49, 63, 72, 75, 84,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194763</th>\n",
       "      <td>221179</td>\n",
       "      <td>Кроме проекта MOXIE, на ней будут представлены...</td>\n",
       "      <td>КромепроектаMOXIE,нанейбудутпредставленыдругие...</td>\n",
       "      <td>[5, 13, 20, 23, 27, 33, 46, 53, 64, 67, 80, 89]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27717</th>\n",
       "      <td>211403</td>\n",
       "      <td>Прибыль в расчете на одну акцию выросла на три...</td>\n",
       "      <td>Прибыльврасчетенаоднуакциювыросланатрипроцента...</td>\n",
       "      <td>[7, 9, 17, 20, 25, 31, 39, 42, 46, 56, 59, 64,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152339</th>\n",
       "      <td>72669</td>\n",
       "      <td>Впрочем, гендиректор ТНТ Роман Петренко опрове...</td>\n",
       "      <td>Впрочем,гендиректорТНТРоманПетренкоопровергэту...</td>\n",
       "      <td>[8, 20, 24, 30, 39, 48, 52, 66, 73, 80, 87, 96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70673</th>\n",
       "      <td>118406</td>\n",
       "      <td>Данные о численности обеих акций были озвучены...</td>\n",
       "      <td>Данныеочисленностиобеихакцийбылиозвученывластя...</td>\n",
       "      <td>[6, 8, 20, 26, 32, 37, 46, 55, 62, 65, 71, 77,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169787</th>\n",
       "      <td>10346</td>\n",
       "      <td>В результате ученым удалось определить, что по...</td>\n",
       "      <td>Врезультатеученымудалосьопределить,чтоподобный...</td>\n",
       "      <td>[1, 12, 19, 27, 39, 43, 52, 61, 70, 72, 82, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>276301</td>\n",
       "      <td>Основная задача миссии — изучение карликовой п...</td>\n",
       "      <td>Основнаязадачамиссии—изучениекарликовойпланеты...</td>\n",
       "      <td>[8, 15, 22, 24, 33, 44, 52, 54, 58, 67]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30039</th>\n",
       "      <td>96826</td>\n",
       "      <td>Быков под эту цель не подходит\", - объяснил Ле...</td>\n",
       "      <td>Быковподэтуцельнеподходит\",-объяснилЛевенталь....</td>\n",
       "      <td>[5, 9, 13, 18, 21, 32, 34, 43, 59, 71, 82, 86,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60971</th>\n",
       "      <td>178064</td>\n",
       "      <td>Причиной отключения стали сбои, из-за которых ...</td>\n",
       "      <td>Причинойотключениясталисбои,из-закоторыхгеймер...</td>\n",
       "      <td>[8, 19, 25, 31, 37, 45, 53, 56, 62, 70, 72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93424</th>\n",
       "      <td>118045</td>\n",
       "      <td>Изначально общая стоимость проекта оценивалась...</td>\n",
       "      <td>Изначальнообщаястоимостьпроектаоцениваласьприм...</td>\n",
       "      <td>[10, 16, 26, 34, 46, 55, 57, 60, 71]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231985</th>\n",
       "      <td>213397</td>\n",
       "      <td>По его словам, прибывшие работники скорой помо...</td>\n",
       "      <td>Поегословам,прибывшиеработникискоройпомощипыта...</td>\n",
       "      <td>[2, 6, 14, 24, 34, 41, 48, 57, 71, 80, 84, 86,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61968</th>\n",
       "      <td>179874</td>\n",
       "      <td>Завершение спасательной операции запечатлел на...</td>\n",
       "      <td>Завершениеспасательнойоперациизапечатлелнафото...</td>\n",
       "      <td>[10, 23, 32, 43, 46, 51, 53, 57, 60, 68, 70, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45930</th>\n",
       "      <td>238480</td>\n",
       "      <td>За 2014 год, согласно официальной статистике, ...</td>\n",
       "      <td>За2014год,согласноофициальнойстатистике,объемд...</td>\n",
       "      <td>[2, 7, 12, 21, 33, 45, 51, 58, 68, 73, 76, 84,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84635</th>\n",
       "      <td>123388</td>\n",
       "      <td>После этого Владимир Колокольцев распорядился ...</td>\n",
       "      <td>ПослеэтогоВладимирКолокольцевраспорядилсяпрове...</td>\n",
       "      <td>[5, 11, 20, 32, 45, 54, 56, 69, 85, 92, 95, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133424</th>\n",
       "      <td>157827</td>\n",
       "      <td>В составе сборной США Бош выиграл золото Олимп...</td>\n",
       "      <td>ВсоставесборнойСШАБошвыигралзолотоОлимпийскихи...</td>\n",
       "      <td>[1, 9, 17, 21, 25, 33, 40, 52, 56, 61, 66, 68]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  \\\n",
       "10782   221169  Атмосфера Земли, для сравнения, состоит на 21 ...   \n",
       "57340   172891  Компания также заверила, что этот факт не окаж...   \n",
       "26451   184070            Об этом сообщается на сайте кинотеатра.   \n",
       "47327    31904  По данным газеты \"Комсомольская правда\", его з...   \n",
       "161950   22579  Об этом заявил министр обороны временного прав...   \n",
       "28327    59409  При этом не уточняется, почему для ответной ак...   \n",
       "194763  221179  Кроме проекта MOXIE, на ней будут представлены...   \n",
       "27717   211403  Прибыль в расчете на одну акцию выросла на три...   \n",
       "152339   72669  Впрочем, гендиректор ТНТ Роман Петренко опрове...   \n",
       "70673   118406  Данные о численности обеих акций были озвучены...   \n",
       "169787   10346  В результате ученым удалось определить, что по...   \n",
       "5890    276301  Основная задача миссии — изучение карликовой п...   \n",
       "30039    96826  Быков под эту цель не подходит\", - объяснил Ле...   \n",
       "60971   178064  Причиной отключения стали сбои, из-за которых ...   \n",
       "93424   118045  Изначально общая стоимость проекта оценивалась...   \n",
       "231985  213397  По его словам, прибывшие работники скорой помо...   \n",
       "61968   179874  Завершение спасательной операции запечатлел на...   \n",
       "45930   238480  За 2014 год, согласно официальной статистике, ...   \n",
       "84635   123388  После этого Владимир Колокольцев распорядился ...   \n",
       "133424  157827  В составе сборной США Бош выиграл золото Олимп...   \n",
       "\n",
       "                                                 no_space  \\\n",
       "10782   АтмосфераЗемли,длясравнения,состоитна21процент...   \n",
       "57340   Компаниятакжезаверила,чтоэтотфактнеокажетнегат...   \n",
       "26451                  Обэтомсообщаетсянасайтекинотеатра.   \n",
       "47327   Поданнымгазеты\"Комсомольскаяправда\",егозадержа...   \n",
       "161950  Обэтомзаявилминистроборонывременногоправительс...   \n",
       "28327   Приэтомнеуточняется,почемудляответнойакциипотр...   \n",
       "194763  КромепроектаMOXIE,нанейбудутпредставленыдругие...   \n",
       "27717   Прибыльврасчетенаоднуакциювыросланатрипроцента...   \n",
       "152339  Впрочем,гендиректорТНТРоманПетренкоопровергэту...   \n",
       "70673   Данныеочисленностиобеихакцийбылиозвученывластя...   \n",
       "169787  Врезультатеученымудалосьопределить,чтоподобный...   \n",
       "5890    Основнаязадачамиссии—изучениекарликовойпланеты...   \n",
       "30039   Быковподэтуцельнеподходит\",-объяснилЛевенталь....   \n",
       "60971   Причинойотключениясталисбои,из-закоторыхгеймер...   \n",
       "93424   Изначальнообщаястоимостьпроектаоцениваласьприм...   \n",
       "231985  Поегословам,прибывшиеработникискоройпомощипыта...   \n",
       "61968   Завершениеспасательнойоперациизапечатлелнафото...   \n",
       "45930   За2014год,согласноофициальнойстатистике,объемд...   \n",
       "84635   ПослеэтогоВладимирКолокольцевраспорядилсяпрове...   \n",
       "133424  ВсоставесборнойСШАБошвыигралзолотоОлимпийскихи...   \n",
       "\n",
       "                                          space_positions  \n",
       "10782                 [9, 16, 20, 31, 39, 42, 45, 53, 56]  \n",
       "57340   [8, 14, 24, 28, 33, 38, 41, 48, 60, 72, 75, 83...  \n",
       "26451                                  [2, 7, 18, 21, 27]  \n",
       "47327   [2, 9, 16, 31, 40, 44, 54, 58, 66, 74, 82, 92,...  \n",
       "161950  [2, 7, 14, 22, 30, 41, 55, 62, 75, 79, 89, 99,...  \n",
       "28327   [3, 8, 11, 23, 30, 34, 43, 49, 63, 72, 75, 84,...  \n",
       "194763    [5, 13, 20, 23, 27, 33, 46, 53, 64, 67, 80, 89]  \n",
       "27717   [7, 9, 17, 20, 25, 31, 39, 42, 46, 56, 59, 64,...  \n",
       "152339  [8, 20, 24, 30, 39, 48, 52, 66, 73, 80, 87, 96...  \n",
       "70673   [6, 8, 20, 26, 32, 37, 46, 55, 62, 65, 71, 77,...  \n",
       "169787  [1, 12, 19, 27, 39, 43, 52, 61, 70, 72, 82, 10...  \n",
       "5890              [8, 15, 22, 24, 33, 44, 52, 54, 58, 67]  \n",
       "30039   [5, 9, 13, 18, 21, 32, 34, 43, 59, 71, 82, 86,...  \n",
       "60971         [8, 19, 25, 31, 37, 45, 53, 56, 62, 70, 72]  \n",
       "93424                [10, 16, 26, 34, 46, 55, 57, 60, 71]  \n",
       "231985  [2, 6, 14, 24, 34, 41, 48, 57, 71, 80, 84, 86,...  \n",
       "61968   [10, 23, 32, 43, 46, 51, 53, 57, 60, 68, 70, 7...  \n",
       "45930   [2, 7, 12, 21, 33, 45, 51, 58, 68, 73, 76, 84,...  \n",
       "84635   [5, 11, 20, 32, 45, 54, 56, 69, 85, 92, 95, 10...  \n",
       "133424     [1, 9, 17, 21, 25, 33, 40, 52, 56, 61, 66, 68]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d49da",
   "metadata": {},
   "source": [
    "Так как в тестовом файле от Авито в основном короткие словосочетания, такие как книгахорошая, оставим из исходного датасета только короткие строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cc55c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество коротких строк: 36160\n",
      "Количество коротких строк: 4285\n",
      "Количество коротких строк: 4023\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[train_df['no_space'].str.len() <= MAX_LEN/2].copy()\n",
    "val_df = val_df[val_df['no_space'].str.len() <= MAX_LEN/2].copy()\n",
    "test_df = test_df[test_df['no_space'].str.len() <= MAX_LEN/2].copy()\n",
    "print(f\"Количество коротких строк: {len(train_df)}\")\n",
    "print(f\"Количество коротких строк: {len(val_df)}\")\n",
    "print(f\"Количество коротких строк: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adfa26e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>no_space</th>\n",
       "      <th>space_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44166</th>\n",
       "      <td>233020</td>\n",
       "      <td>Об этом сообщает Bloomberg.</td>\n",
       "      <td>ОбэтомсообщаетBloomberg.</td>\n",
       "      <td>[2, 7, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228459</th>\n",
       "      <td>43539</td>\n",
       "      <td>Позднее, правда, сайт возобновил работу.</td>\n",
       "      <td>Позднее,правда,сайтвозобновилработу.</td>\n",
       "      <td>[8, 16, 21, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33990</th>\n",
       "      <td>67038</td>\n",
       "      <td>Отмечается лишь, что женщина - московская домо...</td>\n",
       "      <td>Отмечаетсялишь,чтоженщина-московскаядомохозяйка.</td>\n",
       "      <td>[10, 16, 20, 28, 30, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201703</th>\n",
       "      <td>109444</td>\n",
       "      <td>Эту величину они получили раньше срока - в сер...</td>\n",
       "      <td>Этувеличинуониполучилираньшесрока-всерединеиюн...</td>\n",
       "      <td>[3, 12, 16, 25, 32, 38, 40, 42, 51, 56, 61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160018</th>\n",
       "      <td>236352</td>\n",
       "      <td>«Не все», — ответил президент.</td>\n",
       "      <td>«Невсе»,—ответилпрезидент.</td>\n",
       "      <td>[3, 9, 11, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39875</th>\n",
       "      <td>16520</td>\n",
       "      <td>Ракеты могут быть пущены с любого направления ...</td>\n",
       "      <td>Ракетымогутбытьпущеныслюбогонаправленияподлюбы...</td>\n",
       "      <td>[6, 12, 17, 24, 26, 33, 45, 49, 55, 61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111376</th>\n",
       "      <td>223178</td>\n",
       "      <td>Среди кредиторов — Сбербанк, Райффайзенбанк, Б...</td>\n",
       "      <td>Средикредиторов—Сбербанк,Райффайзенбанк,БанкМо...</td>\n",
       "      <td>[5, 16, 18, 28, 44, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93677</th>\n",
       "      <td>258502</td>\n",
       "      <td>Штурмовики станцевали перед зданием лезгинку.</td>\n",
       "      <td>Штурмовикистанцевалипередзданиемлезгинку.</td>\n",
       "      <td>[10, 21, 27, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97177</th>\n",
       "      <td>73249</td>\n",
       "      <td>Свою дебютную пластинку коллектив выпустил в 1...</td>\n",
       "      <td>Своюдебютнуюпластинкуколлективвыпустилв1984году.</td>\n",
       "      <td>[4, 13, 23, 33, 42, 44, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165129</th>\n",
       "      <td>147587</td>\n",
       "      <td>В интервью \"Дождю\" он называл Шойгу своим крес...</td>\n",
       "      <td>Винтервью\"Дождю\"онназывалШойгусвоимкрестнымотц...</td>\n",
       "      <td>[1, 10, 18, 21, 29, 35, 41, 50, 56, 58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184268</th>\n",
       "      <td>264254</td>\n",
       "      <td>Здесь ваши жизни будут подвергаться риску.</td>\n",
       "      <td>Здесьвашижизнибудутподвергатьсяриску.</td>\n",
       "      <td>[5, 10, 16, 22, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192310</th>\n",
       "      <td>254044</td>\n",
       "      <td>Руководство России приняло решение о поддержке...</td>\n",
       "      <td>РуководствоРоссиипринялорешениеоподдержкеэконо...</td>\n",
       "      <td>[11, 18, 26, 34, 36, 46, 56]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220210</th>\n",
       "      <td>49592</td>\n",
       "      <td>В случае признания виновным ему грозит смертна...</td>\n",
       "      <td>Вслучаепризнаниявиновнымемугрозитсмертнаяказнь.</td>\n",
       "      <td>[1, 8, 18, 27, 31, 38, 47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177176</th>\n",
       "      <td>91311</td>\n",
       "      <td>Еще трое беглецов были убиты в ходе спецоперац...</td>\n",
       "      <td>Ещетроебеглецовбылиубитывходеспецоперациипоихп...</td>\n",
       "      <td>[3, 8, 17, 22, 28, 30, 35, 48, 51, 54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198001</th>\n",
       "      <td>213607</td>\n",
       "      <td>По его словам, об этом его попросили сами бойцы.</td>\n",
       "      <td>Поегословам,обэтомегопопросилисамибойцы.</td>\n",
       "      <td>[2, 6, 14, 17, 22, 26, 36, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219367</th>\n",
       "      <td>124506</td>\n",
       "      <td>На покрытых копотью столбах белые экземпляры б...</td>\n",
       "      <td>Напокрытыхкопотьюстолбахбелыеэкземплярыбылибол...</td>\n",
       "      <td>[2, 11, 19, 27, 33, 44, 49, 55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172446</th>\n",
       "      <td>207933</td>\n",
       "      <td>«Потенциал колоссальный.</td>\n",
       "      <td>«Потенциалколоссальный.</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177644</th>\n",
       "      <td>293153</td>\n",
       "      <td>Задача должна быть решена в 2017-2018 годах.</td>\n",
       "      <td>Задачадолжнабытьрешенав2017-2018годах.</td>\n",
       "      <td>[6, 13, 18, 25, 27, 37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209305</th>\n",
       "      <td>100584</td>\n",
       "      <td>Власти утверждают, что на воздух взлетел склад...</td>\n",
       "      <td>Властиутверждают,чтонавоздухвзлетелскладсфейер...</td>\n",
       "      <td>[6, 18, 22, 25, 32, 40, 46, 48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56597</th>\n",
       "      <td>34712</td>\n",
       "      <td>Курс доллара, напротив, вырос почти на восемь ...</td>\n",
       "      <td>Курсдоллара,напротив,выроспочтинавосемькопеекд...</td>\n",
       "      <td>[4, 13, 23, 29, 35, 38, 45, 52, 55, 63]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  \\\n",
       "44166   233020                        Об этом сообщает Bloomberg.   \n",
       "228459   43539           Позднее, правда, сайт возобновил работу.   \n",
       "33990    67038  Отмечается лишь, что женщина - московская домо...   \n",
       "201703  109444  Эту величину они получили раньше срока - в сер...   \n",
       "160018  236352                     «Не все», — ответил президент.   \n",
       "39875    16520  Ракеты могут быть пущены с любого направления ...   \n",
       "111376  223178  Среди кредиторов — Сбербанк, Райффайзенбанк, Б...   \n",
       "93677   258502      Штурмовики станцевали перед зданием лезгинку.   \n",
       "97177    73249  Свою дебютную пластинку коллектив выпустил в 1...   \n",
       "165129  147587  В интервью \"Дождю\" он называл Шойгу своим крес...   \n",
       "184268  264254         Здесь ваши жизни будут подвергаться риску.   \n",
       "192310  254044  Руководство России приняло решение о поддержке...   \n",
       "220210   49592  В случае признания виновным ему грозит смертна...   \n",
       "177176   91311  Еще трое беглецов были убиты в ходе спецоперац...   \n",
       "198001  213607   По его словам, об этом его попросили сами бойцы.   \n",
       "219367  124506  На покрытых копотью столбах белые экземпляры б...   \n",
       "172446  207933                           «Потенциал колоссальный.   \n",
       "177644  293153       Задача должна быть решена в 2017-2018 годах.   \n",
       "209305  100584  Власти утверждают, что на воздух взлетел склад...   \n",
       "56597    34712  Курс доллара, напротив, вырос почти на восемь ...   \n",
       "\n",
       "                                                 no_space  \\\n",
       "44166                            ОбэтомсообщаетBloomberg.   \n",
       "228459               Позднее,правда,сайтвозобновилработу.   \n",
       "33990    Отмечаетсялишь,чтоженщина-московскаядомохозяйка.   \n",
       "201703  Этувеличинуониполучилираньшесрока-всерединеиюн...   \n",
       "160018                         «Невсе»,—ответилпрезидент.   \n",
       "39875   Ракетымогутбытьпущеныслюбогонаправленияподлюбы...   \n",
       "111376  Средикредиторов—Сбербанк,Райффайзенбанк,БанкМо...   \n",
       "93677           Штурмовикистанцевалипередзданиемлезгинку.   \n",
       "97177    Своюдебютнуюпластинкуколлективвыпустилв1984году.   \n",
       "165129  Винтервью\"Дождю\"онназывалШойгусвоимкрестнымотц...   \n",
       "184268              Здесьвашижизнибудутподвергатьсяриску.   \n",
       "192310  РуководствоРоссиипринялорешениеоподдержкеэконо...   \n",
       "220210    Вслучаепризнаниявиновнымемугрозитсмертнаяказнь.   \n",
       "177176  Ещетроебеглецовбылиубитывходеспецоперациипоихп...   \n",
       "198001           Поегословам,обэтомегопопросилисамибойцы.   \n",
       "219367  Напокрытыхкопотьюстолбахбелыеэкземплярыбылибол...   \n",
       "172446                            «Потенциалколоссальный.   \n",
       "177644             Задачадолжнабытьрешенав2017-2018годах.   \n",
       "209305  Властиутверждают,чтонавоздухвзлетелскладсфейер...   \n",
       "56597   Курсдоллара,напротив,выроспочтинавосемькопеекд...   \n",
       "\n",
       "                                    space_positions  \n",
       "44166                                    [2, 7, 16]  \n",
       "228459                              [8, 16, 21, 32]  \n",
       "33990                      [10, 16, 20, 28, 30, 41]  \n",
       "201703  [3, 12, 16, 25, 32, 38, 40, 42, 51, 56, 61]  \n",
       "160018                               [3, 9, 11, 19]  \n",
       "39875       [6, 12, 17, 24, 26, 33, 45, 49, 55, 61]  \n",
       "111376                      [5, 16, 18, 28, 44, 49]  \n",
       "93677                              [10, 21, 27, 35]  \n",
       "97177                   [4, 13, 23, 33, 42, 44, 49]  \n",
       "165129      [1, 10, 18, 21, 29, 35, 41, 50, 56, 58]  \n",
       "184268                          [5, 10, 16, 22, 35]  \n",
       "192310                 [11, 18, 26, 34, 36, 46, 56]  \n",
       "220210                   [1, 8, 18, 27, 31, 38, 47]  \n",
       "177176       [3, 8, 17, 22, 28, 30, 35, 48, 51, 54]  \n",
       "198001               [2, 6, 14, 17, 22, 26, 36, 41]  \n",
       "219367              [2, 11, 19, 27, 33, 44, 49, 55]  \n",
       "172446                                         [10]  \n",
       "177644                      [6, 13, 18, 25, 27, 37]  \n",
       "209305              [6, 18, 22, 25, 32, 40, 46, 48]  \n",
       "56597       [4, 13, 23, 29, 35, 38, 45, 52, 55, 63]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90663b2a",
   "metadata": {},
   "source": [
    "Подготовка данных и датасета для BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1db89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class SpaceDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=MAX_LEN):\n",
    "        self.texts = df['no_space'].tolist()\n",
    "        self.labels = []\n",
    "        for pos_str, txt in zip(df['space_positions'], df['no_space']):\n",
    "            pos = [int(p) for p in pos_str.strip(\"[]\").split(\",\") if p]\n",
    "            label = [0]*len(txt)\n",
    "            for p in pos:\n",
    "                if p < len(label):\n",
    "                    label[p] = 1\n",
    "            if len(label) > max_len:\n",
    "                label = label[:max_len]\n",
    "            self.labels.append(label)\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        txt = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        enc = self.tokenizer(txt, truncation=True, max_length=self.max_len, padding='max_length', return_tensors='pt')\n",
    "        input_ids = enc['input_ids'].squeeze(0)\n",
    "        attention_mask = enc['attention_mask'].squeeze(0)\n",
    "        labels = torch.tensor(label[:self.max_len], dtype=torch.long)\n",
    "        if len(labels) < self.max_len:\n",
    "            pad_len = self.max_len - len(labels)\n",
    "            labels = torch.cat([labels, torch.zeros(pad_len, dtype=torch.long)])\n",
    "        return input_ids, attention_mask, labels\n",
    "\n",
    "train_dataset = SpaceDataset(train_df, tokenizer)\n",
    "val_dataset   = SpaceDataset(val_df, tokenizer)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader    = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97a615",
   "metadata": {},
   "source": [
    "Архитектура и инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe66801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd71ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078773d",
   "metadata": {},
   "source": [
    "Функции для обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12621a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for input_ids, attention_mask, labels in tqdm(loader):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "        loss = criterion(outputs.view(-1, 2), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "            loss = criterion(outputs.view(-1, 2), labels.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            mask = attention_mask.bool()\n",
    "            all_preds.extend(preds[mask].cpu().numpy())\n",
    "            all_labels.extend(labels[mask].cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    p = precision_score(all_labels, all_preds)\n",
    "    r = recall_score(all_labels, all_preds)\n",
    "    return total_loss / len(loader), f1, p, r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0dea7",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31350056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:14<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1175, Val Loss=0.0943, F1=0.4697, P=0.8176, R=0.3295\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:11<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.0883, Val Loss=0.0776, F1=0.6048, P=0.8208, R=0.4788\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:18<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0752, Val Loss=0.0697, F1=0.6978, P=0.7819, R=0.6300\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:18<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.0655, Val Loss=0.0628, F1=0.7403, P=0.7977, R=0.6906\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:20<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.0579, Val Loss=0.0585, F1=0.7566, P=0.8271, R=0.6972\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:23<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.0521, Val Loss=0.0549, F1=0.7914, P=0.8382, R=0.7496\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:23<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.0474, Val Loss=0.0601, F1=0.7922, P=0.8143, R=0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:23<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.0433, Val Loss=0.0556, F1=0.8097, P=0.8387, R=0.7826\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:22<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.0397, Val Loss=0.0545, F1=0.8250, P=0.8448, R=0.8061\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:19<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.0370, Val Loss=0.0531, F1=0.8315, P=0.8557, R=0.8085\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:16<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.0340, Val Loss=0.0537, F1=0.8430, P=0.8681, R=0.8193\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:10<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.0317, Val Loss=0.0557, F1=0.8396, P=0.8619, R=0.8185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:12<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.0303, Val Loss=0.0573, F1=0.8169, P=0.8416, R=0.7936\n",
      "Learning rate reduced to 0.000015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:10<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.0230, Val Loss=0.0497, F1=0.8643, P=0.8809, R=0.8484\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:10<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.0203, Val Loss=0.0506, F1=0.8673, P=0.8824, R=0.8526\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:11<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=0.0191, Val Loss=0.0514, F1=0.8626, P=0.8796, R=0.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:11<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=0.0178, Val Loss=0.0574, F1=0.8673, P=0.8779, R=0.8569\n",
      "Learning rate reduced to 0.000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:13<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=0.0147, Val Loss=0.0564, F1=0.8720, P=0.8813, R=0.8628\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:11<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=0.0135, Val Loss=0.0589, F1=0.8718, P=0.8835, R=0.8603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260/2260 [04:11<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=0.0128, Val Loss=0.0616, F1=0.8743, P=0.8821, R=0.8666\n",
      "Saved best checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 997/2260 [01:53<02:23,  8.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m min_delta = \u001b[32m0.001\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     val_loss, f1, p, r = validate(model, val_loader, criterion, device)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Train Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Val Loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, P=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, R=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     12\u001b[39m     loss.backward()\n\u001b[32m     13\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss / \u001b[38;5;28mlen\u001b[39m(loader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "epochs_no_improve = 0\n",
    "patience = 7\n",
    "min_delta = 0.001\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, f1, p, r = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, F1={f1:.4f}, P={p:.4f}, R={r:.4f}\")\n",
    "\n",
    "    # Проверка на улучшение F1\n",
    "    if f1 - best_f1 > min_delta:\n",
    "        best_f1 = f1\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, \"best_epoch_5.pt\"))\n",
    "        print(\"Saved best checkpoint.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"No improvement for {patience} epochs. Stopping training.\")\n",
    "        break\n",
    "\n",
    "    # уменьшение learning rate, если нет улучшений\n",
    "    if epochs_no_improve > 0 and epochs_no_improve % 2 == 0:\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] *= 0.5\n",
    "        print(f\"Learning rate reduced to {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38debfb",
   "metadata": {},
   "source": [
    "Функция для проверки метрики на тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "209c762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_file(model, tokenizer, df, max_len=MAX_LEN):\n",
    "    if 'no_space' not in df.columns:\n",
    "        df['no_space'] = df['tetext_no_spaces'] \n",
    "    if 'space_positions' not in df.columns and 'true_positions' in df.columns:\n",
    "        df['space_positions'] = df['true_positions']\n",
    "\n",
    "    dataset = SpaceDataset(df, tokenizer, max_len=max_len)\n",
    "    loader = DataLoader(dataset, batch_size=16)\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "            mask = attention_mask.bool()\n",
    "            all_preds.extend(preds[mask].cpu().numpy())\n",
    "            all_labels.extend(labels[mask].cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    p = precision_score(all_labels, all_preds)\n",
    "    r = recall_score(all_labels, all_preds)\n",
    "    print(f\"Evaluation: F1={f1:.4f}, Precision={p:.4f}, Recall={r:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70bd22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "best_model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, \"best_epoch_5.pt\"), map_location=device))\n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f04f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: F1=0.8725, Precision=0.8794, Recall=0.8657\n"
     ]
    }
   ],
   "source": [
    "evaluate_file(best_model, tokenizer, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7965e3f8",
   "metadata": {},
   "source": [
    "Обработка файла задания от Авито"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48accabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset_1937770_3.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Заменяем первую запятую в каждой строке на точку с запятой\n",
    "corrected_lines = []\n",
    "for line in lines:\n",
    "    # Разделяем строку по первой запятой\n",
    "    parts = line.split(\",\", 1)\n",
    "    if len(parts) == 2:\n",
    "        # Объединяем с разделителем ';'\n",
    "        corrected_line = f\"{parts[0]};{parts[1]}\"\n",
    "        corrected_lines.append(corrected_line)\n",
    "    else:\n",
    "        # Если строка не содержит запятых (например, заголовок), оставляем как есть\n",
    "        corrected_lines.append(line)\n",
    "\n",
    "with open(\"corrected_dataset.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.writelines(corrected_lines)\n",
    "\n",
    "task_data = pd.read_csv(\"corrected_dataset.txt\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3dc90b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_no_spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>куплюайфон14про</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ищудомвПодмосковье</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>сдаюквартирусмебельюитехникой</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>новыйдивандоставканедорого</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>отдамдаромкошку</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>Янеусну.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>Весна-яуженегреюпио.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>Весна-скоровырастеттрава.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>Весна-выпосмотрите,каккрасиво.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>Весна-гдемояголова?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                  text_no_spaces\n",
       "0        0                 куплюайфон14про\n",
       "1        1              ищудомвПодмосковье\n",
       "2        2   сдаюквартирусмебельюитехникой\n",
       "3        3      новыйдивандоставканедорого\n",
       "4        4                 отдамдаромкошку\n",
       "...    ...                             ...\n",
       "1000  1000                        Янеусну.\n",
       "1001  1001            Весна-яуженегреюпио.\n",
       "1002  1002       Весна-скоровырастеттрава.\n",
       "1003  1003  Весна-выпосмотрите,каккрасиво.\n",
       "1004  1004             Весна-гдемояголова?\n",
       "\n",
       "[1005 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a3e20",
   "metadata": {},
   "source": [
    "Подготовка датасета для инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c7027ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.texts = df['text_no_spaces'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        txt = self.texts[idx]\n",
    "        enc = self.tokenizer(\n",
    "            txt, truncation=True, max_length=self.max_len,\n",
    "            padding='max_length', return_tensors='pt'\n",
    "        )\n",
    "        input_ids = enc['input_ids'].squeeze(0)\n",
    "        attention_mask = enc['attention_mask'].squeeze(0)\n",
    "        return input_ids, attention_mask, txt\n",
    "\n",
    "task_dataset = TaskDataset(task_data, tokenizer, MAX_LEN)\n",
    "task_loader = DataLoader(task_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9e434",
   "metadata": {},
   "source": [
    "Загрузка сохраненной модели и подготовка ее к инференсу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2803ed7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, \"best_epoch_5.pt\")))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab06d8",
   "metadata": {},
   "source": [
    "Инференс модели и восстановление текста с пробелами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e2a70aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions added to task_data and saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "pred_positions = []\n",
    "pred_texts = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, texts in task_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        for i, txt in enumerate(texts):\n",
    "            mask = attention_mask[i].bool()\n",
    "            pred_labels = preds[i][mask].cpu().numpy()\n",
    "            positions = [j for j, label in enumerate(pred_labels) if label == 1]\n",
    "\n",
    "            # Восстанавливаем текст с пробелами\n",
    "            new_text = \"\"\n",
    "            for idx, char in enumerate(txt):\n",
    "                if idx in positions:\n",
    "                    new_text += \" \"\n",
    "                new_text += char\n",
    "\n",
    "            pred_positions.append(positions)\n",
    "            pred_texts.append(new_text)\n",
    "\n",
    "task_data['predicted_positions'] = pred_positions\n",
    "task_data['predicted_text'] = pred_texts\n",
    "\n",
    "task_data.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Predictions added to task_data and saved to submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
